{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vSg6IN5QQ7FG"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8e7uKaHEpSPD"},"source":["# **LOAD MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nU0AMWzRmYd"},"outputs":[],"source":["import joblib\n","import cv2 as cv\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f5ijBt9JXmdJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SVC from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}],"source":["# Load the trained model\n","loaded_model = joblib.load('/content/drive/MyDrive/ML Project/ML_Project_02/ML Project/Deployment/Trained_Models/model.pkl')\n","\n","# Define the class names\n","class_names = ['glioma_tumor', 'meningioma_tumor', 'normal', 'pituitary_tumor']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bFmiW1gKX9TC"},"outputs":[],"source":["def preprocess_image(image_path, target_size=(30, 10)):\n","    \"\"\"Preprocess the input image for model prediction.\"\"\"\n","    # Load the image\n","    img = cv.imread(image_path)\n","    # Resize the image to the target size\n","    img_resized = cv.resize(img, target_size)\n","    # Convert image to grayscale if required by the model\n","    gray_img = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n","    # Flatten the image if the model expects a 1D array\n","    img_flattened = gray_img.flatten()\n","    # Make sure the feature length matches what the model expects\n","    if len(img_flattened) != 300:  # Adjust this number to match the expected feature length\n","        raise ValueError(f\"Expected 300 features, but got {len(img_flattened)} features.\")\n","\n","    return img_flattened"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7G7GH9hkYEjZ"},"outputs":[],"source":["def predict_image(image_path):\n","    \"\"\"Predict the class of the input image using the trained model.\"\"\"\n","    # Preprocess the image\n","    img_preprocessed = preprocess_image(image_path)\n","    # Make prediction\n","    prediction = loaded_model.predict([img_preprocessed])\n","    # Map the prediction to class names\n","    predicted_class = class_names[prediction[0]]\n","    return predicted_class"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nBhoIIimYHGP"},"outputs":[{"name":"stdout","output_type":"stream","text":["The predicted class for the image is: meningioma_tumor\n"]}],"source":["# Example usage\n","image_path = '/content/drive/MyDrive/ML Project/ML_Project_02/ML Project/Test Data/meningioma_tumor/M_1.jpg'\n","predicted_class = predict_image(image_path)\n","print(f'The predicted class for the image is: {predicted_class}')\n"]},{"cell_type":"markdown","metadata":{"id":"wwkC8vdHbZGZ"},"source":["# **GRADIO FUNCTION**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Q5755pNVbgSg"},"outputs":[],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"elapsed":288747,"status":"ok","timestamp":1724410683775,"user":{"displayName":"Muhammad Asif Khan","userId":"03533809648664392750"},"user_tz":-300},"id":"ahVsMyUEet-E","outputId":"ea74cf81-0da3-4f66-9de9-fbd05e3133f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://289f8ed923dc7fc137.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://289f8ed923dc7fc137.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 \u003c\u003e https://aee5409587fe3d91d5.gradio.live\n","Killing tunnel 127.0.0.1:7861 \u003c\u003e https://289f8ed923dc7fc137.gradio.live\n"]}],"source":["import numpy as np\n","import gradio as gr\n","\n","def sepia(input_img):\n","    sepia_filter = np.array([\n","        [0.393, 0.769, 0.189],\n","        [0.349, 0.686, 0.168],\n","        [0.272, 0.534, 0.131]\n","    ])\n","    sepia_img = input_img.dot(sepia_filter.T)\n","    sepia_img /= sepia_img.max()\n","    return sepia_img\n","\n","demo = gr.Interface(sepia, gr.Image(), \"image\")\n","if __name__ == \"__main__\":\n","    demo.launch(debug=True)\n"]},{"cell_type":"markdown","metadata":{"id":"VYAyvzMZnPM5"},"source":["# UPGRADE NO# 2"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1724410942194,"user":{"displayName":"Muhammad Asif Khan","userId":"03533809648664392750"},"user_tz":-300},"id":"IMLmeMDAe7iX","outputId":"27866677-9414-480c-cd0d-f2081c4fc506"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://a7c61949a8e6f00907.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://a7c61949a8e6f00907.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import cv2 as cv\n","import joblib\n","import gradio as gr\n","\n","# Load the trained model\n","loaded_model = joblib.load('/content/drive/MyDrive/ML Project/ML_Project_02/ML Project/Deployment/Trained_Models/model.pkl')\n","\n","# Define the class names\n","class_names = ['glioma_tumor', 'meningioma_tumor', 'normal', 'pituitary_tumor']\n","\n","def preprocess_image(image, target_size=(30, 10)):\n","    \"\"\"Preprocess the input image for model prediction.\"\"\"\n","    # Resize the image\n","    img_resized = cv.resize(image, target_size)\n","    # Convert image to grayscale\n","    gray_img = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n","    # Flatten the image\n","    img_flattened = gray_img.flatten()\n","    # Make sure the feature length matches what the model expects\n","    if len(img_flattened) != 300:  # Adjust this number to match the expected feature length\n","        raise ValueError(f\"Expected 300 features, but got {len(img_flattened)} features.\")\n","    return gray_img, img_flattened\n","\n","def predict_image(image):\n","    \"\"\"Predict the class of the input image using the trained model and return the processed image.\"\"\"\n","    # Preprocess the image\n","    processed_image, img_preprocessed = preprocess_image(image)\n","    # Make prediction\n","    prediction = loaded_model.predict([img_preprocessed])\n","    # Map the prediction to class names\n","    predicted_class = class_names[prediction[0]]\n","    # Convert processed_image to RGB format for display\n","    processed_image_rgb = cv.cvtColor(processed_image, cv.COLOR_GRAY2RGB)\n","    return predicted_class, processed_image_rgb\n","\n","# Gradio interface\n","demo = gr.Interface(\n","    fn=predict_image,\n","    inputs=gr.Image(type=\"numpy\"),\n","    outputs=[gr.Text(), gr.Image()]\n",")\n","\n","if __name__ == \"__main__\":\n","    demo.launch()\n"]},{"cell_type":"markdown","metadata":{"id":"ZinvzpEjmg9b"},"source":["# UPGRADE NO# 3"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"elapsed":709,"status":"ok","timestamp":1724408754012,"user":{"displayName":"Muhammad Asif Khan","userId":"03533809648664392750"},"user_tz":-300},"id":"_xf1-CIsg0wk","outputId":"238bc9c4-908f-4231-858e-9377148f6381"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://aee5409587fe3d91d5.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://aee5409587fe3d91d5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Define the class names\n","class_names = ['glioma_tumor', 'meningioma_tumor', 'normal', 'pituitary_tumor']\n","\n","def preprocess_image(image, target_size=(30, 10)):\n","    \"\"\"Preprocess the input image for model prediction.\"\"\"\n","    # Convert the image to a format suitable for OpenCV\n","    img = np.array(image)\n","    # Resize the image to the target size\n","    img_resized = cv.resize(img, target_size)\n","    # Convert image to grayscale if required by the model\n","    gray_img = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n","    # Flatten the image if the model expects a 1D array\n","    img_flattened = gray_img.flatten()\n","    # Make sure the feature length matches what the model expects\n","    if len(img_flattened) != 300:  # Adjust this number to match the expected feature length\n","        raise ValueError(f\"Expected 300 features, but got {len(img_flattened)} features.\")\n","\n","    return img_flattened\n","\n","def predict_image(image):\n","    \"\"\"Predict the class of the input image using the trained model.\"\"\"\n","    # Preprocess the image\n","    img_preprocessed = preprocess_image(image)\n","    # Make prediction\n","    prediction = loaded_model.predict([img_preprocessed])\n","    # Map the prediction to class names\n","    predicted_class = class_names[prediction[0]]\n","\n","    return predicted_class, image\n","\n","def feedback(predicted_class, actual_class):\n","    \"\"\"Provide feedback on the prediction.\"\"\"\n","    return \"Correct\" if predicted_class == actual_class else \"Wrong\"\n","\n","# Gradio interface\n","def gradio_interface(image, actual_class):\n","    predicted_class, processed_image = predict_image(image)\n","    result = feedback(predicted_class, actual_class)\n","    return processed_image, predicted_class, result\n","\n","# Create the Gradio interface\n","demo = gr.Interface(\n","    fn=gradio_interface,\n","    inputs=[gr.Image(), gr.Textbox(label=\"Actual Class\")],\n","    outputs=[gr.Image(), \"text\", \"text\"],\n","    live=True\n",")\n","\n","if __name__ == \"__main__\":\n","    demo.launch()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1724408754012,"user":{"displayName":"Muhammad Asif Khan","userId":"03533809648664392750"},"user_tz":-300},"id":"7LcXOyqslflX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPXDvAH8OxuaHMJb8kABSJe","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}